{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('../data/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_cat'] = pd.cut(df['median_income'],\n",
    "                          bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                          labels=[1, 2, 3, 4, 5])\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42,\n",
    "                                       stratify=df['income_cat'])\n",
    "# Drop 'income_cat' feature\n",
    "for set_ in (train_set, test_set):\n",
    "    set_.drop('income_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train_set features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_tr_labels = train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(data):\n",
    "    # Get Column names contains nulls\n",
    "    columns_with_null_values = data.columns[data.isnull().any()].tolist()\n",
    "    for col in columns_with_null_values:\n",
    "        if data[col].dtype == 'object':\n",
    "            imputer = SimpleImputer(strategy='most_frequent')\n",
    "        else:  # Numeric Columns\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "        data[[col]] = imputer.fit_transform(data[[col]])\n",
    "    return data\n",
    "\n",
    "\n",
    "housing_tr = impute_missing_values(housing_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_numerical_categorical(data):\n",
    "    num_df = data.select_dtypes(include=[np.number])\n",
    "    cat_df = data.select_dtypes(include=[\"object\"])\n",
    "    return num_df, cat_df\n",
    "\n",
    "\n",
    "housing_tr_num, _ = separate_numerical_categorical(housing_tr)\n",
    "\n",
    "# Find and Drop Outliers\n",
    "isolation_forest = IsolationForest(random_state=42)\n",
    "outlier_pred = isolation_forest.fit_predict(housing_tr_num)\n",
    "\n",
    "housing_tr = housing_tr.iloc[outlier_pred == 1]\n",
    "housing_tr_labels = housing_tr_labels.iloc[outlier_pred == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Custom Class for finding Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.kmeans_ = KMeans(self.n_clusters, random_state=self.random_state)\n",
    "        self.kmeans_.fit(X, sample_weight=sample_weight)\n",
    "        return self  # always return self!\n",
    "\n",
    "    def transform(self, X):\n",
    "        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n",
    "\n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return [f\"Cluster {i} similarity\" for i in range(self.n_clusters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_ratio(X):\n",
    "    return X[:, [0]] / X[:, [1]]\n",
    "\n",
    "\n",
    "def ratio_name(function_transformer, feature_names_in):\n",
    "    return [\"ratio\"]\n",
    "\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        FunctionTransformer(column_ratio,\n",
    "                            feature_names_out=ratio_name),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    FunctionTransformer(np.log, feature_names_out=\"one-to-one\"),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "sqrt_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    FunctionTransformer(np.sqrt, validate=True,\n",
    "                        inverse_func=np.square, feature_names_out=\"one-to-one\"),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "cluster_simil = ClusterSimilarity(n_clusters=10, gamma=1., random_state=42)\n",
    "\n",
    "default_num_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\")\n",
    ")\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"bedrooms\", ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n",
    "    (\"room_per_house\", ratio_pipeline(), [\"total_rooms\", \"households\"]),\n",
    "    (\"people_per_house\", ratio_pipeline(), [\"population\", \"households\"]),\n",
    "    (\"log\", log_pipeline, [\"population\", \"median_income\"]),\n",
    "    (\"sqrt\", sqrt_pipeline, [\"total_bedrooms\", \"total_rooms\", \"households\"]),\n",
    "    (\"geo\", cluster_simil, [\"latitude\", \"longitude\"]),\n",
    "    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "],\n",
    "    remainder=default_num_pipeline)  # one column remaining: housing_median_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14396, 24)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_tr_prepared = preprocessing.fit_transform(housing_tr)\n",
    "housing_tr_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bedrooms__ratio', 'room_per_house__ratio',\n",
       "       'people_per_house__ratio', 'log__population', 'log__median_income',\n",
       "       'sqrt__total_bedrooms', 'sqrt__total_rooms', 'sqrt__households',\n",
       "       'geo__Cluster 0 similarity', 'geo__Cluster 1 similarity',\n",
       "       'geo__Cluster 2 similarity', 'geo__Cluster 3 similarity',\n",
       "       'geo__Cluster 4 similarity', 'geo__Cluster 5 similarity',\n",
       "       'geo__Cluster 6 similarity', 'geo__Cluster 7 similarity',\n",
       "       'geo__Cluster 8 similarity', 'geo__Cluster 9 similarity',\n",
       "       'cat__ocean_proximity_<1H OCEAN', 'cat__ocean_proximity_INLAND',\n",
       "       'cat__ocean_proximity_ISLAND', 'cat__ocean_proximity_NEAR BAY',\n",
       "       'cat__ocean_proximity_NEAR OCEAN', 'remainder__housing_median_age'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
